{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFHJTIF48xLs"
      },
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "# Retrieval-Augmented generation (RAG)\n",
        "\n",
        "RAG is a technique for augmenting LLM knowledge with additional, often private or real-time, data.\n",
        "\n",
        "LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model’s cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
        "\n",
        "<img src=\"../figures/RAG-process.png\" >\n",
        "\n",
        "Introducing `ChakyBot`, an innovative chatbot designed to assist Chaky (the instructor) and TA (Gun) in explaining the lesson of the NLP course to students. Leveraging LangChain technology, ChakyBot excels in retrieving information from documents, ensuring a seamless and efficient learning experience for students engaging with the NLP curriculum.\n",
        "\n",
        "1. Prompt\n",
        "2. Retrieval\n",
        "3. Memory\n",
        "4. Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xt0uFaW8xLu",
        "outputId": "398cfe39-f8b9-41e2-8cc4-9f73b0f4663d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.0\n",
            "  Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.0)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.0)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.9 (from langchain==0.1.0)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.0) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.0)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community<0.1,>=0.0.9 (from langchain==0.1.0)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.26-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.23-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.22-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.7->langchain==0.1.0) (3.7.1)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.27-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.7->langchain==0.1.0)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.0) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain==0.1.0) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.0 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.21.1 mypy-extensions-1.0.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting accelerate==0.25.0\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.25.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.25.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting transformers==4.36.2\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.36.2\n",
            "Collecting bitsandbytes==0.41.2\n",
            "  Downloading bitsandbytes-0.41.2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.2\n",
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.36.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers==2.2.2) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=328f21144bd7dc11a6d0f59964cbfaf53e9a17a3a92f8aa96f3bb4b44d15d962\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2\n",
            "Collecting InstructorEmbedding==1.0.1\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: InstructorEmbedding\n",
            "Successfully installed InstructorEmbedding-1.0.1\n",
            "Collecting pymupdf==1.23.8\n",
            "  Downloading PyMuPDF-1.23.8-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.7 (from pymupdf==1.23.8)\n",
            "  Downloading PyMuPDFb-1.23.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.23.7 pymupdf-1.23.8\n",
            "Collecting faiss-gpu==1.7.2\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting faiss-cpu==1.7.4\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m612.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ],
      "source": [
        "#langchain library\n",
        "!pip install langchain==0.1.0\n",
        "#LLM\n",
        "!pip install accelerate==0.25.0\n",
        "!pip install transformers==4.36.2\n",
        "!pip install bitsandbytes==0.41.2\n",
        "#Text Embedding\n",
        "!pip install sentence-transformers==2.2.2\n",
        "!pip install InstructorEmbedding==1.0.1\n",
        "#vectorstore\n",
        "!pip install pymupdf==1.23.8\n",
        "!pip install faiss-gpu==1.7.2\n",
        "!pip install faiss-cpu==1.7.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxnXMPCf8xLu",
        "outputId": "777cefe7-e60c-4a97-c5b1-c96c780f4088"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "# Set GPU device\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CaZY5Fe8xLv"
      },
      "source": [
        "## 1. Prompt\n",
        "\n",
        "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xatFC1Ek8xLv",
        "outputId": "cfef645d-6bff-48f7-d95d-8dd037493e5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context', 'question'], template=\"I'm AIT GPT to answer all the question about the institution.\\n    {context}\\n    Question: {question}\\n    Answer:\")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "    I'm AIT GPT to answer all the question about the institution.\n",
        "    {context}\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    \"\"\".strip()\n",
        "\n",
        "PROMPT = PromptTemplate.from_template(\n",
        "    template = prompt_template\n",
        ")\n",
        "\n",
        "PROMPT\n",
        "#using str.format\n",
        "#The placeholder is defined using curly brackets: {} {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "o3D30y308xLv",
        "outputId": "d43593b1-9ba8-4b21-adeb-1c38fa6f82e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm AIT GPT to answer all the question about the institution.\\n    AIT is in Pathum Thani, Thailand\\n    Question: Where is AIT?\\n    Answer:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "PROMPT.format(\n",
        "    context = \"AIT is in Pathum Thani, Thailand\",\n",
        "    question = \"Where is AIT?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izx_oDKA8xLv"
      },
      "source": [
        "Note : [How to improve prompting (Zero-shot, Few-shot, Chain-of-Thought, etc.](https://github.com/chaklam-silpasuwanchai/Natural-Language-Processing/blob/main/Code/05%20-%20RAG/advance/cot-tot-prompting.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4yg-vNI8xLw"
      },
      "source": [
        "## 2. Retrieval\n",
        "\n",
        "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code).\n",
        "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
        "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
        "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
        "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKU7EQMS8xLw"
      },
      "source": [
        "### 2.1 Document Loaders\n",
        "Use document loaders to load data from a source as Document's. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
        "\n",
        "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)\n",
        "\n",
        "[Download Document](https://web.stanford.edu/~jurafsky/slp3/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "69zIfTL38xLw"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "nlp_docs = 'AIT.pdf'\n",
        "\n",
        "loader = PyMuPDFLoader(nlp_docs)\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "d8M0l7ti8xLw"
      },
      "outputs": [],
      "source": [
        "# documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvKmMF5Z8xLw",
        "outputId": "5bca39af-9d20-4cc7-f17d-7de938404fb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmaivcFb8xLw",
        "outputId": "73fa7e6c-f91a-4d1f-faaa-40cb87fba226"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"Asian Institute of Technology\\n15th for SDG#1 No Poverty\\n58th for SDG#17 Partnerships for the Goals\\n64th for SDG#14 Life Below Water\\n67th for SDG#2 Zero Hunger\\n80th for SDG#15 Life on Land\\n100 - 200th for SDG#6 Clean Water and Sanitation\\n100 - 200th for SDG#11 Sustainable Cities and\\nCommunities\\n100 - 200th for Overall Impact\\nIn the 2020 THE Impact Rankings,[10] AIT ranked globally:\\n19th for SDG#1 No Poverty\\n86th for SDG#2 Zero Hunger\\n100 - 200th for SDG#6 Clean Water and Sanitation\\n100 - 200th for SDG#14 Life Below Water\\n100 - 200th for SDG#15 Life on Land\\n300 - 400th for Overall Impact\\nIn 2020 QS Global MBA Rankings,[11] AIT Master of Business Administration (MBA) program ranked 14th in\\nAsia and 1st in Thailand. It also ranked 7th in Asia for Diversity and 18th in the world for Return on Investment.\\nIn the QS World University Rankings by Subject 2020, AIT ranked 2nd in Thailand in Engineering and\\nTechnology,[12] 151-200th in the world in Environmental Studies[13] and in Architecture & Built\\nEnvironment,[14] and 201-250th in the world in Civil and Structural Engineering[15] and in Agricultural and\\nForestry.[16]\\nAIT operates as a self-contained international community at its campus in Pathumthani Province, some 40\\nkilometres (25 mi) north of Bangkok, Thailand. Besides laboratories and academic buildings, the main campus\\nincludes housing, sports, and medical facilities, a conference center, and a library with over 230,000 volumes\\nand 830 print and online periodicals.\\nAIT was hosted by the Faculty of Engineering, Chulalongkorn University, Thailand, before it moved to its\\npresent campus in November 1973. Currently, it is located in the Rangsit area next to Thammasat University\\n(Rangsit Campus), about 65 kilometers from the Suvarnabhumi Airport.\\nAIT has a remote campus called AIT Center in Vietnam. It was established in 1993 under the memorandum of\\nunderstanding between the Vietnam Ministry of Education and Training and the AIT.[17] At that time AITCV\\nwas the first international institution in Vietnam and the first AIT campus outside Thailand.\\nAIT's student body comes from more than 50 countries, with Thailand contributing to about one-third. It has\\nalways been international, with international donors offering scholarships to AIT students for capacity building.\\nFull Scholarships\\nLocation\\nStudent body\\nScholarships\\n\", metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 1, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "documents[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNe5xOau8xLw"
      },
      "source": [
        "### 2.2 Document Transformers\n",
        "\n",
        "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "LLvBZjD58xLw"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 700,\n",
        "    chunk_overlap = 100\n",
        ")\n",
        "\n",
        "doc = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_14ZtCs8xLw",
        "outputId": "6d4a7688-97dc-4edd-bb05-10042228f5bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='in \\nengineering, \\nadvanced\\ntechnologies, sustainable development, and management and planning.\\nIt aims to promote technological change and sustainable development in\\nthe Asia-Pacific region, through higher education, research, and\\noutreach.[1]\\nFounded in 1959 as SEATO Graduate School of Engineering, it\\nreceives funding from organizations and governments around the\\nworld.\\nIn 1967, The Constituent Assembly of Thailand approved legislation\\nfor the Charter of the newly named Asian Institute of Technology in\\nOctober. The Asian Institute of Technology Enabling Act was\\npublished in the Royal Thai Government Gazette in November the\\nsame year. AIT became independent of SEATO as an institution of', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 0, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "doc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwppcTGe8xLw",
        "outputId": "dac0c3d7-8a61-4a27-c3fa-af37c5c22c17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9vlp4q68xLx"
      },
      "source": [
        "### 2.3 Text Embedding Models\n",
        "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
        "\n",
        "*Note* Instructor Model : [Huggingface](gingface.co/hkunlp/instructor-base) | [Paper](https://arxiv.org/abs/2212.09741)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7nPkrKN8xLx",
        "outputId": "f7fee9ba-793d-417e-8f5e-321605f12102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "\n",
        "model_name = 'hkunlp/instructor-base'\n",
        "\n",
        "embedding_model = HuggingFaceInstructEmbeddings(\n",
        "    model_name = model_name,\n",
        "    model_kwargs = {\"device\" : device}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N5MnNfn8xLx"
      },
      "source": [
        "### 2.4 Vector Stores\n",
        "\n",
        "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "is5lzqyi8xLx"
      },
      "outputs": [],
      "source": [
        "#locate vectorstore\n",
        "vector_path = 'vector-store'\n",
        "if not os.path.exists(vector_path):\n",
        "    os.makedirs(vector_path)\n",
        "    print('create path done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "C-yBs79t8xLx"
      },
      "outputs": [],
      "source": [
        "#save vector locally\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectordb = FAISS.from_documents(\n",
        "    documents = doc,\n",
        "    embedding = embedding_model\n",
        ")\n",
        "\n",
        "db_file_name = 'nlp_stanford'\n",
        "\n",
        "vectordb.save_local(\n",
        "    folder_path = os.path.join(vector_path, db_file_name),\n",
        "    index_name = 'nlp' #default index\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk_VZ_4L8xLx"
      },
      "source": [
        "### 2.5 retrievers\n",
        "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1xOC8nLx8xLx"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectordb = FAISS.load_local(\n",
        "    folder_path = os.path.join(vector_path, db_file_name),\n",
        "    embeddings = embedding_model,\n",
        "    index_name = 'nlp' #default index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8o9l170a8xLx"
      },
      "outputs": [],
      "source": [
        "#ready to use\n",
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2inyhCjU8xLx",
        "outputId": "aa2f6bd4-f9c0-4962-d43f-dffee5ff5433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Asian Institute of\\nTechnology\\nAIT\\nFormer\\nnames\\nSEATO Graduate\\nSchool of\\nEngineering\\nMotto\\n'Social Impact with\\nInnovation'\\nEstablished\\n1959\\nPresident\\nKazuo Yamamoto\\nAcademic\\nstaff\\nAbout 100\\nStudents\\n1,700+\\nAddress\\n58 Moo 9, Km42,\\nPaholyothin\\nHighway, Khlong\\nLuang, Pathum\\nThani, Thailand\\nAffiliations\\nIAU, ASAIHL,\\nGMSARN,\\nProSPER.Net,\\nACTU, ANSO\\nWebsite\\nwww.ait.ac.th (http\\ns://www.ait.ac.th/)\\nAsian Institute of Technology\\nThe Asian Institute of Technology (AIT), founded in 1959, is an\\ninternational organization for higher education situated 40km north of\\nBangkok, \\nThailand. \\nIt \\nspecializes \\nin \\nengineering, \\nadvanced\\ntechnologies, sustainable development, and management and planning.\", metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 0, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              " Document(page_content='The campus of Asian Institute of Technology is host to several international and non-governmental organizations\\nincluding the Regional Resource Center in Asia and the Pacific (UNEP RRC.AP) (www.rrcap.unep.org) (http\\ns://web.archive.org/web/20101130124318/http://www.rrcap.unep.org/), and the Regional Integrated Multi-\\nHazard Early Warning System for Africa and Asia (RIMES) (www.rimes.int) (http://www.rimes.int/).\\nIt also hosts the global secretariat of the International Partnership for Expanding Waste Management Services of\\nLocal Authorities (IPLA),[23] while the regional secretariat is hosted by UN HABITAT. Four UN agencies,', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 2, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              " Document(page_content='in \\nengineering, \\nadvanced\\ntechnologies, sustainable development, and management and planning.\\nIt aims to promote technological change and sustainable development in\\nthe Asia-Pacific region, through higher education, research, and\\noutreach.[1]\\nFounded in 1959 as SEATO Graduate School of Engineering, it\\nreceives funding from organizations and governments around the\\nworld.\\nIn 1967, The Constituent Assembly of Thailand approved legislation\\nfor the Charter of the newly named Asian Institute of Technology in\\nOctober. The Asian Institute of Technology Enabling Act was\\npublished in the Royal Thai Government Gazette in November the\\nsame year. AIT became independent of SEATO as an institution of', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 0, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              " Document(page_content='Asian Institute of Technology\\n15th for SDG#1 No Poverty\\n58th for SDG#17 Partnerships for the Goals\\n64th for SDG#14 Life Below Water\\n67th for SDG#2 Zero Hunger\\n80th for SDG#15 Life on Land\\n100 - 200th for SDG#6 Clean Water and Sanitation\\n100 - 200th for SDG#11 Sustainable Cities and\\nCommunities\\n100 - 200th for Overall Impact\\nIn the 2020 THE Impact Rankings,[10] AIT ranked globally:\\n19th for SDG#1 No Poverty\\n86th for SDG#2 Zero Hunger\\n100 - 200th for SDG#6 Clean Water and Sanitation\\n100 - 200th for SDG#14 Life Below Water\\n100 - 200th for SDG#15 Life on Land\\n300 - 400th for Overall Impact\\nIn 2020 QS Global MBA Rankings,[11] AIT Master of Business Administration (MBA) program ranked 14th in', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 1, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''})]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "retriever.get_relevant_documents(\"Asian Institute of Technology\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7bE8TqN8xLy"
      },
      "source": [
        "## 3. Memory\n",
        "\n",
        "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
        "\n",
        "You may want to use this class directly if you are managing memory outside of a chain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2sNwzKx8xLy",
        "outputId": "b04cb2b6-f551-4627-a667-1b853e35c240"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatMessageHistory(messages=[])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "history = ChatMessageHistory()\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "w-GJ7els8xLy"
      },
      "outputs": [],
      "source": [
        "history.add_user_message('hi')\n",
        "history.add_ai_message('Whats up?')\n",
        "history.add_user_message('How are you')\n",
        "history.add_ai_message('I\\'m quite good. How about you?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1detYpC8xLy",
        "outputId": "329bdcbe-b9ab-4421-f217-695d7a57769d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpHE3nY_8xLy"
      },
      "source": [
        "### 3.1 Memory types\n",
        "\n",
        "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios.\n",
        "- Converstaion Buffer\n",
        "- Converstaion Buffer Window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wflPsC0S8xLy"
      },
      "source": [
        "What variables get returned from memory\n",
        "\n",
        "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h3Hya-Y8xLy"
      },
      "source": [
        "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOMb9AjL8xLy"
      },
      "source": [
        "#### Converstaion Buffer\n",
        "This memory allows for storing messages and then extracts the messages in a variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFTVPBD68xLy",
        "outputId": "c967e80c-bea4-4725-d15e-5633bfdc9c3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZU51KJf8xLz",
        "outputId": "28073272-9537-499d-9458-77ac05532891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='hi'),\n",
              "  AIMessage(content=\"What's up?\"),\n",
              "  HumanMessage(content='How are you?'),\n",
              "  AIMessage(content=\"I'm quite good. How about you?\")]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages = True)\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2HeoSPb8xLz"
      },
      "source": [
        "#### Conversation Buffer Window\n",
        "- it keeps a list of the interactions of the conversation over time.\n",
        "- it only uses the last K interactions.\n",
        "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBH2hZ-M8xLz",
        "outputId": "b4a375b9-bffc-4968-fc26-39be9e174dcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFNA6ARe8xLz"
      },
      "source": [
        "## 4. Chain\n",
        "\n",
        "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
        "\n",
        "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
        "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
        "- it formats the prompt template using the input key values provided (and also memory key values, if available),\n",
        "- it passes the formatted string to LLM and returns the LLM output.\n",
        "\n",
        "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "bzkabOwE8xLz"
      },
      "outputs": [],
      "source": [
        "# %cd ./models\n",
        "# !git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0JnXMHC8xLz",
        "outputId": "97375b6f-a57b-4a89-b895-2d9a573ffe50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "from langchain import HuggingFacePipeline\n",
        "import torch\n",
        "\n",
        "model_id = 'lmsys/fastchat-t5-3b-v1.0'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id)\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "bitsandbyte_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "    bnb_4bit_compute_dtype = torch.float16,\n",
        "    bnb_4bit_use_double_quant = True\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config = bitsandbyte_config, #caution Nvidia\n",
        "    device_map = 'auto',\n",
        "    load_in_8bit = True\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    task=\"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens = 256,\n",
        "    model_kwargs = {\n",
        "        \"temperature\" : 0,\n",
        "        \"repetition_penalty\": 1.5\n",
        "    }\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline = pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n13_Rfm8xL0"
      },
      "source": [
        "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
        "\n",
        "- `retriever` : Retriever to use to fetch documents.\n",
        "\n",
        "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
        "\n",
        "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
        "\n",
        "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
        "\n",
        "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
        "\n",
        "- `return_generated_question` : Return the generated question as part of the final result.\n",
        "\n",
        "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvFPdXOX8xL0"
      },
      "source": [
        "`question_generator`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "6lQY0ttC8xL0"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGtj4XDx8xL0",
        "outputId": "731103eb-2dc0-4372-94b5-b877e4aa8dfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "CONDENSE_QUESTION_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "15iwtoBZ8xL0"
      },
      "outputs": [],
      "source": [
        "question_generator = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = CONDENSE_QUESTION_PROMPT,\n",
        "    verbose = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4tLhyQ98xL0",
        "outputId": "28acc3b0-a051-40de-9311-30c5bd2ae996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "Human:What is Machine Learning\n",
            "AI:\n",
            "Human:What is Deep Learning\n",
            "AI:\n",
            "Follow Up Input: Comparing both of them\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': 'Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:',\n",
              " 'question': 'Comparing both of them',\n",
              " 'text': '<pad> What  is  the  difference  between  Machine  Learning  and  Deep  Learning  AI?\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "query = 'Comparing both of them'\n",
        "chat_history = \"Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:\"\n",
        "\n",
        "question_generator({'chat_history' : chat_history, \"question\" : query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-XFseo78xL0"
      },
      "source": [
        "`combine_docs_chain`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOBLgzdO8xL0",
        "outputId": "00a4d532-0021-47d3-d4a6-65ca48fb9b74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm AIT GPT to answer all the question about the institution.\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7bd32bf3bc40>)), document_variable_name='context')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "doc_chain = load_qa_chain(\n",
        "    llm = llm,\n",
        "    chain_type = 'stuff',\n",
        "    prompt = PROMPT,\n",
        "    verbose = True\n",
        ")\n",
        "doc_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-fnCXkY8xL0",
        "outputId": "7099ff5e-5e58-4763-ae5c-c5eed5d3d0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm AIT GPT to answer all the question about the institution.\n",
            "    Asian Institute of\n",
            "Technology\n",
            "AIT\n",
            "Former\n",
            "names\n",
            "SEATO Graduate\n",
            "School of\n",
            "Engineering\n",
            "Motto\n",
            "'Social Impact with\n",
            "Innovation'\n",
            "Established\n",
            "1959\n",
            "President\n",
            "Kazuo Yamamoto\n",
            "Academic\n",
            "staff\n",
            "About 100\n",
            "Students\n",
            "1,700+\n",
            "Address\n",
            "58 Moo 9, Km42,\n",
            "Paholyothin\n",
            "Highway, Khlong\n",
            "Luang, Pathum\n",
            "Thani, Thailand\n",
            "Affiliations\n",
            "IAU, ASAIHL,\n",
            "GMSARN,\n",
            "ProSPER.Net,\n",
            "ACTU, ANSO\n",
            "Website\n",
            "www.ait.ac.th (http\n",
            "s://www.ait.ac.th/)\n",
            "Asian Institute of Technology\n",
            "The Asian Institute of Technology (AIT), founded in 1959, is an\n",
            "international organization for higher education situated 40km north of\n",
            "Bangkok, \n",
            "Thailand. \n",
            "It \n",
            "specializes \n",
            "in \n",
            "engineering, \n",
            "advanced\n",
            "technologies, sustainable development, and management and planning.\n",
            "\n",
            "The campus of Asian Institute of Technology is host to several international and non-governmental organizations\n",
            "including the Regional Resource Center in Asia and the Pacific (UNEP RRC.AP) (www.rrcap.unep.org) (http\n",
            "s://web.archive.org/web/20101130124318/http://www.rrcap.unep.org/), and the Regional Integrated Multi-\n",
            "Hazard Early Warning System for Africa and Asia (RIMES) (www.rimes.int) (http://www.rimes.int/).\n",
            "It also hosts the global secretariat of the International Partnership for Expanding Waste Management Services of\n",
            "Local Authorities (IPLA),[23] while the regional secretariat is hosted by UN HABITAT. Four UN agencies,\n",
            "\n",
            "in \n",
            "engineering, \n",
            "advanced\n",
            "technologies, sustainable development, and management and planning.\n",
            "It aims to promote technological change and sustainable development in\n",
            "the Asia-Pacific region, through higher education, research, and\n",
            "outreach.[1]\n",
            "Founded in 1959 as SEATO Graduate School of Engineering, it\n",
            "receives funding from organizations and governments around the\n",
            "world.\n",
            "In 1967, The Constituent Assembly of Thailand approved legislation\n",
            "for the Charter of the newly named Asian Institute of Technology in\n",
            "October. The Asian Institute of Technology Enabling Act was\n",
            "published in the Royal Thai Government Gazette in November the\n",
            "same year. AIT became independent of SEATO as an institution of\n",
            "\n",
            "Asian Institute of Technology\n",
            "15th for SDG#1 No Poverty\n",
            "58th for SDG#17 Partnerships for the Goals\n",
            "64th for SDG#14 Life Below Water\n",
            "67th for SDG#2 Zero Hunger\n",
            "80th for SDG#15 Life on Land\n",
            "100 - 200th for SDG#6 Clean Water and Sanitation\n",
            "100 - 200th for SDG#11 Sustainable Cities and\n",
            "Communities\n",
            "100 - 200th for Overall Impact\n",
            "In the 2020 THE Impact Rankings,[10] AIT ranked globally:\n",
            "19th for SDG#1 No Poverty\n",
            "86th for SDG#2 Zero Hunger\n",
            "100 - 200th for SDG#6 Clean Water and Sanitation\n",
            "100 - 200th for SDG#14 Life Below Water\n",
            "100 - 200th for SDG#15 Life on Land\n",
            "300 - 400th for Overall Impact\n",
            "In 2020 QS Global MBA Rankings,[11] AIT Master of Business Administration (MBA) program ranked 14th in\n",
            "    Question: Asian Institute of Technology\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_documents': [Document(page_content=\"Asian Institute of\\nTechnology\\nAIT\\nFormer\\nnames\\nSEATO Graduate\\nSchool of\\nEngineering\\nMotto\\n'Social Impact with\\nInnovation'\\nEstablished\\n1959\\nPresident\\nKazuo Yamamoto\\nAcademic\\nstaff\\nAbout 100\\nStudents\\n1,700+\\nAddress\\n58 Moo 9, Km42,\\nPaholyothin\\nHighway, Khlong\\nLuang, Pathum\\nThani, Thailand\\nAffiliations\\nIAU, ASAIHL,\\nGMSARN,\\nProSPER.Net,\\nACTU, ANSO\\nWebsite\\nwww.ait.ac.th (http\\ns://www.ait.ac.th/)\\nAsian Institute of Technology\\nThe Asian Institute of Technology (AIT), founded in 1959, is an\\ninternational organization for higher education situated 40km north of\\nBangkok, \\nThailand. \\nIt \\nspecializes \\nin \\nengineering, \\nadvanced\\ntechnologies, sustainable development, and management and planning.\", metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 0, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='The campus of Asian Institute of Technology is host to several international and non-governmental organizations\\nincluding the Regional Resource Center in Asia and the Pacific (UNEP RRC.AP) (www.rrcap.unep.org) (http\\ns://web.archive.org/web/20101130124318/http://www.rrcap.unep.org/), and the Regional Integrated Multi-\\nHazard Early Warning System for Africa and Asia (RIMES) (www.rimes.int) (http://www.rimes.int/).\\nIt also hosts the global secretariat of the International Partnership for Expanding Waste Management Services of\\nLocal Authorities (IPLA),[23] while the regional secretariat is hosted by UN HABITAT. Four UN agencies,', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 2, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='in \\nengineering, \\nadvanced\\ntechnologies, sustainable development, and management and planning.\\nIt aims to promote technological change and sustainable development in\\nthe Asia-Pacific region, through higher education, research, and\\noutreach.[1]\\nFounded in 1959 as SEATO Graduate School of Engineering, it\\nreceives funding from organizations and governments around the\\nworld.\\nIn 1967, The Constituent Assembly of Thailand approved legislation\\nfor the Charter of the newly named Asian Institute of Technology in\\nOctober. The Asian Institute of Technology Enabling Act was\\npublished in the Royal Thai Government Gazette in November the\\nsame year. AIT became independent of SEATO as an institution of', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 0, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='Asian Institute of Technology\\n15th for SDG#1 No Poverty\\n58th for SDG#17 Partnerships for the Goals\\n64th for SDG#14 Life Below Water\\n67th for SDG#2 Zero Hunger\\n80th for SDG#15 Life on Land\\n100 - 200th for SDG#6 Clean Water and Sanitation\\n100 - 200th for SDG#11 Sustainable Cities and\\nCommunities\\n100 - 200th for Overall Impact\\nIn the 2020 THE Impact Rankings,[10] AIT ranked globally:\\n19th for SDG#1 No Poverty\\n86th for SDG#2 Zero Hunger\\n100 - 200th for SDG#6 Clean Water and Sanitation\\n100 - 200th for SDG#14 Life Below Water\\n100 - 200th for SDG#15 Life on Land\\n300 - 400th for Overall Impact\\nIn 2020 QS Global MBA Rankings,[11] AIT Master of Business Administration (MBA) program ranked 14th in', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 1, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''})],\n",
              " 'question': 'Asian Institute of Technology',\n",
              " 'output_text': '<pad>  AIT  is  an  international  organization  for  higher  education  situated  40km  north  of  Bangkok,  Thailand.  It  specializes  in  engineering,  advanced  technologies,  sustainable  development,  and  management  and  planning.  The  campus  of  AIT  is  host  to  several  international  and  non-governmental  organizations  including  the  Regional  Resource  Center  in  Asia  and  the  Pacific  (UNEP  RRC.AP)  (www.rrcap.unep.org)  (http  s://web.archive.org/web/20101130124318/http://www.rrcap.unep.org/),  and  the  Regional  Integrated  Multi- Hazard  Early  Warning  System  for  Africa  and  Asia  (RIMES)  (www.rimes.int)  (http://www.rimes.int/).  It  also  hosts  the  global  secretariat  of  the  International  Partnership  for  Expanding  Waste  Management '}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "query = \"Asian Institute of Technology\"\n",
        "input_document = retriever.get_relevant_documents(query)\n",
        "\n",
        "doc_chain({'input_documents':input_document, 'question':query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3FJsLlx8xL1",
        "outputId": "84266bf0-6fb0-4c49-b7eb-670ec052df9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm AIT GPT to answer all the question about the institution.\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7bd32bf3bc40>)), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7bd32bf3bc40>)), return_source_documents=True, get_chat_history=<function <lambda> at 0x7bd22a64a830>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7bd22b271600>))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    k=3,\n",
        "    memory_key = \"chat_history\",\n",
        "    return_messages = True,\n",
        "    output_key = 'answer'\n",
        ")\n",
        "\n",
        "chain = ConversationalRetrievalChain(\n",
        "    retriever=retriever,\n",
        "    question_generator=question_generator,\n",
        "    combine_docs_chain=doc_chain,\n",
        "    return_source_documents=True,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    get_chat_history=lambda h : h\n",
        ")\n",
        "chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s3HnTrq8xL1"
      },
      "source": [
        "## 5. Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iltp-FHq8xL1",
        "outputId": "a310a39e-f3fe-4b47-863e-923b92ec09f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm AIT GPT to answer all the question about the institution.\n",
            "    chive/2010/9/Report-from-Swedens-least-known-university/). Retrieved 17 June 2019.\n",
            "49. \"Something for Everyone\" (https://www.bangkokpost.com/lifestyle/interview/430220/something-fo\n",
            "r-everyone). Bangkok Post. Retrieved 17 June 2019.\n",
            "50. \"Condolence- Prof. Thomas H. Evans\" (https://www.ait.ac.th/2000/04/condolence/). 25 April\n",
            "2000. Retrieved 3 September 2018.\n",
            "51. \"AIT People\" (https://apps.ait.ac.th/people/). Asian Institute of Technology. Retrieved 14 June\n",
            "2020.\n",
            "52. \"Dr. Prasarn Trairatvorakul\" (https://www.bot.or.th/English/AboutBOT/RolesAndHistory/Governor/\n",
            "Pages/Prasarn.aspx). Retrieved 22 November 2019.\n",
            "\n",
            "Name\n",
            "Degree\n",
            "Degree\n",
            "Year\n",
            "Notability\n",
            "Notes\n",
            "Boonsrang\n",
            "Niumpradit\n",
            "D. Eng.\n",
            "1978\n",
            "Former Thai Army chief\n",
            "Mao Chi-kuo\n",
            "M. Eng.\n",
            "(Community &\n",
            "Regional\n",
            "Development)\n",
            "1975\n",
            "Former Premier of the Republic of China\n",
            "Yu Xiaogang\n",
            "M.Sc.\n",
            "(Interdisciplinary\n",
            "Natural\n",
            "Resource\n",
            "Development\n",
            "and\n",
            "Management)\n",
            "1993\n",
            "Among the six winners of the 2009 Ramon\n",
            "Magsaysay Awards\n",
            "Imtiaz Gilani\n",
            "M. Eng.\n",
            "(Structural\n",
            "Engineering and\n",
            "Construction)\n",
            "1971\n",
            "Provisional Minister of Education for the Government\n",
            "of Khyber Pakhtunkhwa\n",
            "Bindu Lohani\n",
            "Ph.D.\n",
            "(Environmental\n",
            "Engineering)\n",
            "1977\n",
            "Former Vice President Asian Development Bank\n",
            "\n",
            "students constitute the majority of the student body, with Southeast Asia (Thailand and Viet Nam) and South\n",
            "Asia (India, Nepal, Pakistan, Sri Lanka) usually contributing the majority of students\n",
            "Prof. Kazuo Yamamoto is currently the interim president of AIT, succeeding Dr. Eden Y Woon on 1 September\n",
            "2022.[43] Previous presidents include Professor Milton E. Bender Jr. (from USA),[44] Professor Harold E.\n",
            "Hoelscher (from USA), Professor Robert B. Banks (from USA),[45] Professor Alastair M. North (from\n",
            "Scotland),[46][47] Professor Roger GH Downer (Ireland/Canada), Professor Jean-Louis Armand (from France),\n",
            "\n",
            "57. \"Somprasong Boonyachai\" (https://www.marketscreener.com/business-leaders/Sumate-Tanthuw\n",
            "anit-075W7P-E/biography). Retrieved 25 November 2019.\n",
            "58. \"Chaovalit Ekabut\" (https://www.scb.co.th/en/about-us/board-of-director/mr-chaovalit-ekabut.htm\n",
            "l). Retrieved 25 November 2019.\n",
            "59. Preecha, Ekkunagul. \"Preecha Ekkunagul, President/CEO, Central Pattana PCL\" (https://www.bl\n",
            "oomberg.com/profile/person/5497567). BloomBerg.\n",
            "60. \"AIT alumnus is Premier of Taiwan\" (https://www.ait.ac.th/2015/02/ait-alumnus-is-premier-of-taiw\n",
            "an/). 23 February 2015. Retrieved 3 September 2018.\n",
            "61. \"AIT Alumnus wins Ramon Magsaysay Award of 2009\" (https://www.ait.ac.th/2009/08/ait-alumnu\n",
            "    Question: Who are you by the way?\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Who are you by the way?',\n",
              " 'chat_history': [],\n",
              " 'answer': '<pad>  I  am  AIT  GPT  (Global  Partnership  Team)  to  answer  all  the  question  about  the  institution.\\n',\n",
              " 'source_documents': [Document(page_content='chive/2010/9/Report-from-Swedens-least-known-university/). Retrieved 17 June 2019.\\n49. \"Something for Everyone\" (https://www.bangkokpost.com/lifestyle/interview/430220/something-fo\\nr-everyone). Bangkok Post. Retrieved 17 June 2019.\\n50. \"Condolence- Prof. Thomas H. Evans\" (https://www.ait.ac.th/2000/04/condolence/). 25 April\\n2000. Retrieved 3 September 2018.\\n51. \"AIT People\" (https://apps.ait.ac.th/people/). Asian Institute of Technology. Retrieved 14 June\\n2020.\\n52. \"Dr. Prasarn Trairatvorakul\" (https://www.bot.or.th/English/AboutBOT/RolesAndHistory/Governor/\\nPages/Prasarn.aspx). Retrieved 22 November 2019.', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 11, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='Name\\nDegree\\nDegree\\nYear\\nNotability\\nNotes\\nBoonsrang\\nNiumpradit\\nD. Eng.\\n1978\\nFormer Thai Army chief\\nMao Chi-kuo\\nM. Eng.\\n(Community &\\nRegional\\nDevelopment)\\n1975\\nFormer Premier of the Republic of China\\nYu Xiaogang\\nM.Sc.\\n(Interdisciplinary\\nNatural\\nResource\\nDevelopment\\nand\\nManagement)\\n1993\\nAmong the six winners of the 2009 Ramon\\nMagsaysay Awards\\nImtiaz Gilani\\nM. Eng.\\n(Structural\\nEngineering and\\nConstruction)\\n1971\\nProvisional Minister of Education for the Government\\nof Khyber Pakhtunkhwa\\nBindu Lohani\\nPh.D.\\n(Environmental\\nEngineering)\\n1977\\nFormer Vice President Asian Development Bank', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 8, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='students constitute the majority of the student body, with Southeast Asia (Thailand and Viet Nam) and South\\nAsia (India, Nepal, Pakistan, Sri Lanka) usually contributing the majority of students\\nProf. Kazuo Yamamoto is currently the interim president of AIT, succeeding Dr. Eden Y Woon on 1 September\\n2022.[43] Previous presidents include Professor Milton E. Bender Jr. (from USA),[44] Professor Harold E.\\nHoelscher (from USA), Professor Robert B. Banks (from USA),[45] Professor Alastair M. North (from\\nScotland),[46][47] Professor Roger GH Downer (Ireland/Canada), Professor Jean-Louis Armand (from France),', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 6, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='57. \"Somprasong Boonyachai\" (https://www.marketscreener.com/business-leaders/Sumate-Tanthuw\\nanit-075W7P-E/biography). Retrieved 25 November 2019.\\n58. \"Chaovalit Ekabut\" (https://www.scb.co.th/en/about-us/board-of-director/mr-chaovalit-ekabut.htm\\nl). Retrieved 25 November 2019.\\n59. Preecha, Ekkunagul. \"Preecha Ekkunagul, President/CEO, Central Pattana PCL\" (https://www.bl\\noomberg.com/profile/person/5497567). BloomBerg.\\n60. \"AIT alumnus is Premier of Taiwan\" (https://www.ait.ac.th/2015/02/ait-alumnus-is-premier-of-taiw\\nan/). 23 February 2015. Retrieved 3 September 2018.\\n61. \"AIT Alumnus wins Ramon Magsaysay Award of 2009\" (https://www.ait.ac.th/2009/08/ait-alumnu', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 11, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''})]}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "prompt_question = \"Who are you by the way?\"\n",
        "answer = chain({\"question\":prompt_question})\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSHv14gr8xL1",
        "outputId": "6fc41e45-5a0d-4c4d-c9cc-65e7be8ce609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Who are you by the way?'), AIMessage(content='<pad>  I  am  AIT  GPT  (Global  Partnership  Team)  to  answer  all  the  question  about  the  institution.\\n')]\n",
            "Follow Up Input: Asian Institute of Technology\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm AIT GPT to answer all the question about the institution.\n",
            "    Asian Institute of\n",
            "Technology\n",
            "AIT\n",
            "Former\n",
            "names\n",
            "SEATO Graduate\n",
            "School of\n",
            "Engineering\n",
            "Motto\n",
            "'Social Impact with\n",
            "Innovation'\n",
            "Established\n",
            "1959\n",
            "President\n",
            "Kazuo Yamamoto\n",
            "Academic\n",
            "staff\n",
            "About 100\n",
            "Students\n",
            "1,700+\n",
            "Address\n",
            "58 Moo 9, Km42,\n",
            "Paholyothin\n",
            "Highway, Khlong\n",
            "Luang, Pathum\n",
            "Thani, Thailand\n",
            "Affiliations\n",
            "IAU, ASAIHL,\n",
            "GMSARN,\n",
            "ProSPER.Net,\n",
            "ACTU, ANSO\n",
            "Website\n",
            "www.ait.ac.th (http\n",
            "s://www.ait.ac.th/)\n",
            "Asian Institute of Technology\n",
            "The Asian Institute of Technology (AIT), founded in 1959, is an\n",
            "international organization for higher education situated 40km north of\n",
            "Bangkok, \n",
            "Thailand. \n",
            "It \n",
            "specializes \n",
            "in \n",
            "engineering, \n",
            "advanced\n",
            "technologies, sustainable development, and management and planning.\n",
            "\n",
            "Asia and 1st in Thailand. It also ranked 7th in Asia for Diversity and 18th in the world for Return on Investment.\n",
            "In the QS World University Rankings by Subject 2020, AIT ranked 2nd in Thailand in Engineering and\n",
            "Technology,[12] 151-200th in the world in Environmental Studies[13] and in Architecture & Built\n",
            "Environment,[14] and 201-250th in the world in Civil and Structural Engineering[15] and in Agricultural and\n",
            "Forestry.[16]\n",
            "AIT operates as a self-contained international community at its campus in Pathumthani Province, some 40\n",
            "kilometres (25 mi) north of Bangkok, Thailand. Besides laboratories and academic buildings, the main campus\n",
            "\n",
            "AIT Alumni Association, Thailand Chapter (https://web.archive.org/web/20060319175710/http://w\n",
            "ww.aitthai.or.th/)\n",
            "AIT videos on YouTube (https://www.youtube.com/user/aitasia)\n",
            "AIT Alumni in Vietnam (https://web.archive.org/web/20120722021252/http://360.aitaa.vn/)\n",
            "Unified International Bachelor-Master Degree Program (http://www.unified.ait.ac.th/)\n",
            "Retrieved from \"https://en.wikipedia.org/w/index.php?title=Asian_Institute_of_Technology&oldid=1209069273\"\n",
            "\n",
            "includes housing, sports, and medical facilities, a conference center, and a library with over 230,000 volumes\n",
            "and 830 print and online periodicals.\n",
            "AIT was hosted by the Faculty of Engineering, Chulalongkorn University, Thailand, before it moved to its\n",
            "present campus in November 1973. Currently, it is located in the Rangsit area next to Thammasat University\n",
            "(Rangsit Campus), about 65 kilometers from the Suvarnabhumi Airport.\n",
            "AIT has a remote campus called AIT Center in Vietnam. It was established in 1993 under the memorandum of\n",
            "understanding between the Vietnam Ministry of Education and Training and the AIT.[17] At that time AITCV\n",
            "    Question: <pad> What  is  the  Asian  Institute  of  Technology  (AIT)?\n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Asian Institute of Technology',\n",
              " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
              "  AIMessage(content='<pad>  I  am  AIT  GPT  (Global  Partnership  Team)  to  answer  all  the  question  about  the  institution.\\n')],\n",
              " 'answer': '<pad>  The  Asian  Institute  of  Technology  (AIT)  is  an  international  organization  for  higher  education  situated  40km  north  of  Bangkok,  Thailand.  It  specializes  in  engineering,  advanced  technologies,  sustainable  development,  and  management  and  planning.\\n',\n",
              " 'source_documents': [Document(page_content=\"Asian Institute of\\nTechnology\\nAIT\\nFormer\\nnames\\nSEATO Graduate\\nSchool of\\nEngineering\\nMotto\\n'Social Impact with\\nInnovation'\\nEstablished\\n1959\\nPresident\\nKazuo Yamamoto\\nAcademic\\nstaff\\nAbout 100\\nStudents\\n1,700+\\nAddress\\n58 Moo 9, Km42,\\nPaholyothin\\nHighway, Khlong\\nLuang, Pathum\\nThani, Thailand\\nAffiliations\\nIAU, ASAIHL,\\nGMSARN,\\nProSPER.Net,\\nACTU, ANSO\\nWebsite\\nwww.ait.ac.th (http\\ns://www.ait.ac.th/)\\nAsian Institute of Technology\\nThe Asian Institute of Technology (AIT), founded in 1959, is an\\ninternational organization for higher education situated 40km north of\\nBangkok, \\nThailand. \\nIt \\nspecializes \\nin \\nengineering, \\nadvanced\\ntechnologies, sustainable development, and management and planning.\", metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 0, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='Asia and 1st in Thailand. It also ranked 7th in Asia for Diversity and 18th in the world for Return on Investment.\\nIn the QS World University Rankings by Subject 2020, AIT ranked 2nd in Thailand in Engineering and\\nTechnology,[12] 151-200th in the world in Environmental Studies[13] and in Architecture & Built\\nEnvironment,[14] and 201-250th in the world in Civil and Structural Engineering[15] and in Agricultural and\\nForestry.[16]\\nAIT operates as a self-contained international community at its campus in Pathumthani Province, some 40\\nkilometres (25 mi) north of Bangkok, Thailand. Besides laboratories and academic buildings, the main campus', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 1, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='AIT Alumni Association, Thailand Chapter (https://web.archive.org/web/20060319175710/http://w\\nww.aitthai.or.th/)\\nAIT videos on YouTube (https://www.youtube.com/user/aitasia)\\nAIT Alumni in Vietnam (https://web.archive.org/web/20120722021252/http://360.aitaa.vn/)\\nUnified International Bachelor-Master Degree Program (http://www.unified.ait.ac.th/)\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Asian_Institute_of_Technology&oldid=1209069273\"', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 12, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''}),\n",
              "  Document(page_content='includes housing, sports, and medical facilities, a conference center, and a library with over 230,000 volumes\\nand 830 print and online periodicals.\\nAIT was hosted by the Faculty of Engineering, Chulalongkorn University, Thailand, before it moved to its\\npresent campus in November 1973. Currently, it is located in the Rangsit area next to Thammasat University\\n(Rangsit Campus), about 65 kilometers from the Suvarnabhumi Airport.\\nAIT has a remote campus called AIT Center in Vietnam. It was established in 1993 under the memorandum of\\nunderstanding between the Vietnam Ministry of Education and Training and the AIT.[17] At that time AITCV', metadata={'source': 'AIT.pdf', 'file_path': 'AIT.pdf', 'page': 1, 'total_pages': 13, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Chromium', 'producer': 'Skia/PDF m121', 'creationDate': \"D:20240320125911+00'00'\", 'modDate': \"D:20240320125911+00'00'\", 'trapped': ''})]}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "prompt_question = \"Asian Institute of Technology\"\n",
        "answer = chain({\"question\":prompt_question})\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qZxNC25TMYfE",
        "outputId": "7b14d386-71c5-4258-ae42-978a811ba4fb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad>  The  Asian  Institute  of  Technology  (AIT)  is  an  international  organization  for  higher  education  situated  40km  north  of  Bangkok,  Thailand.  It  specializes  in  engineering,  advanced  technologies,  sustainable  development,  and  management  and  planning.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "agzKOlFXMZVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}